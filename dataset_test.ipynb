{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import sklearn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "        openml_ids = {\n",
    "            'iris': 61,  # 150 x 5 - 3 (n_samples x n_feat - n_classes)\n",
    "            'pendigits': 32,  # 10992 x 17 - 10\n",
    "            'glass': 41,  # 214 x 10 - 7 (really 6)\n",
    "            'segment': 36,  # 2310 x 19 - 7\n",
    "            'vehicle': 54,  # 846 x 19 - 4\n",
    "            'vowel': 307,  # 990 x 13 - 11 <- This has cat feat to deal with\n",
    "            'wine': 187,  # 178 x 14 - 3\n",
    "            'abalone': 1557,  # 4177 x 9 - 3 <- Firts cat feat\n",
    "            'balance-scale': 11,  # 625 x 5 - 3\n",
    "            'car': 21,  # 1728 x 7 - 4 <- All categoric\n",
    "            'ecoli': 39,  # 336 x 8 - 8\n",
    "            'satimage': 182,  # 6435 x 37 - 6\n",
    "            'collins': 478,  # 500 x 5 - 6 <- The last feat is cat (but is number as str)\n",
    "            'cardiotocography': 1466,  # 2126 x 35 - 10\n",
    "            'JapaneseVowels': 375,  # 9961 x 14 - 9\n",
    "            'autoUniv-au6-1000': 1555,  # 1000 x 300 - 4 <- This has cat feat to deal with\n",
    "            'autoUniv-au6-750': 1549,  # 750 x 300 - 4  <- This has cat feat to deal with\n",
    "            'analcatdata_dmft': 469,  # 797 x 4 - 6  <- This has cat feat to deal with\n",
    "            'autoUniv-au7-1100': 1552,  # 1100 x 12 - 5 <- This has cat feat to deal with\n",
    "            'GesturePhaseSegmentationProcessed': 4538,  # 9873 x 32 - 5\n",
    "            'autoUniv-au7-500': 1554,  # 500 x 300 - 4  <- This has cat feat to deal with\n",
    "            'mfeat-zernike': 22,  # 2000 x 48 - 10\n",
    "            'zoo': 62,  # 101 x 16 - 7 <- This has dichotomus feat to deal with\n",
    "            'page-blocks': 30,  # 5473 x 10 - 5\n",
    "            'yeast': 181,  # 1484 x 8 - 10\n",
    "            'flags': 285,  # 194 x 29 - 8  <- This has cat feat to deal with\n",
    "            'visualizing_livestock': 685,  # 280 x 8 - 3 <- This has cat feat to deal with\n",
    "            'diggle_table_a2': 694,  # 310 x 8 - 10\n",
    "            'prnn_fglass': 952,  # 214 x 9 - 6\n",
    "            'confidence': 468,  # 72 x 3 - 6\n",
    "            'fl2000': 477,  # 67 x 15 - 5\n",
    "            'blood-transfusion': 1464,  # 748 x 4 - 2\n",
    "            'banknote-authentication': 1462,  # 1372 x 4 - 2\n",
    "            'cifar10': 40927, # 60000 x (32x32x3=3072) - 10\n",
    "            'breast-tissue': 15,  # 699 x 9 - 2\n",
    "            'cholesterol': 141,  # 10^6 x 18 - 4  <- This has cat feat to deal with\n",
    "            'liver-disorders': 145,  # 10^6 x 12 - 11  <- This has cat feat to deal with\n",
    "            'pasture': 294,  # 6435 x 36 - 6\n",
    "            'eucalyptus': 180,  # 110393 x 54 - 7 <- This has cat feat to deal with\n",
    "            'dermatology': 35,  # 366 x 34 - 6 #X = X.astype(np.float64).values should be used\n",
    "            'optdigits': 28,  # 5620 x 64 - 10\n",
    "            'cmc': 23,  # 1473 x 9 - 3\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to Datasets/raw_datasets\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/raw_datasets\\MNIST\\raw\\train-images-idx3-ubyte.gz to Datasets/raw_datasets\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to Datasets/raw_datasets\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/raw_datasets\\MNIST\\raw\\train-labels-idx1-ubyte.gz to Datasets/raw_datasets\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to Datasets/raw_datasets\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/raw_datasets\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to Datasets/raw_datasets\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to Datasets/raw_datasets\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Datasets/raw_datasets\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to Datasets/raw_datasets\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.__dict__['MNIST'](\n",
    "    root='Datasets/raw_datasets', \n",
    "    train=True, \n",
    "    transform=transform, \n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.__dict__['MNIST'](\n",
    "    root='Datasets/raw_datasets', \n",
    "    train=False, \n",
    "    transform=transform, \n",
    "    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.to(torch.float32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.unique(train_dataset.targets))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51592"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.unique(train_dataset.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 7, 0,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(train_dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 6, 5,  ..., 5, 6, 8]),\n",
       " tensor([   53,     1,     2,  ..., 51219, 51220, 51221]))"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(train_dataset.targets, sorted=True, return_inverse=True, return_counts=False, dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(train_dataset.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num_samples = train_dataset.data.shape[0]\n",
    "train_dataset.data.to(torch.float32).view((train_num_samples,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "\n",
    "train_dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
