{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script reproduces what the main.py function does but divided into its parts so we can visualize the whole process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import Data_handling\n",
    "from src.weakener import Weakener\n",
    "from src.model import MLP\n",
    "from utils.datasets_generation import generate_dataset\n",
    "import utils.losses as losses\n",
    "from utils.train_test_loop import train_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 10\n",
    "dataset_base_path = 'Datasets/weak_datasets'\n",
    "dataset = 'mnist'\n",
    "corruption = 'Noisy_Patrini_MNIST'\n",
    "corr_p = 0.7\n",
    "corr_n = None\n",
    "loss_type = 'Forward'\n",
    "\n",
    "for i in range(reps):\n",
    "        generate_dataset(dataset=dataset,corruption=corruption,corr_p=corr_p,repetitions=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "Epoch 10/100: Train Loss: 0.2252, Train Acc: 0.9746, Test Acc: 0.9689, Train Detached Loss: 0.0017, Test Detached Loss: 0.0036, Learning Rate: 0.001000\n",
      "Epoch 20/100: Train Loss: 0.1899, Train Acc: 0.9860, Test Acc: 0.9716, Train Detached Loss: 0.0012, Test Detached Loss: 0.0042, Learning Rate: 0.001000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m     mlp \u001b[38;5;241m=\u001b[39m MLP(Data\u001b[38;5;241m.\u001b[39mnum_features, [Data\u001b[38;5;241m.\u001b[39mnum_features], Weak\u001b[38;5;241m.\u001b[39mc, dropout_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, bn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m     optim \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(mlp\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m     mlp,results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcorr_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorr_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mrep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Bwd = FwdBwdLoss(pinv(M),I_c)\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Fwd = FwdBwdLoss(I_d,M)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danibacaicoa\\vscode_projects\\ForwardBackard_losses\\utils\\train_test_loop.py:33\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, trainloader, testloader, optimizer, loss_fn, num_epochs, corr_p, rep, sound)\u001b[0m\n\u001b[0;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m---> 33\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvl\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     34\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\danibacaicoa\\vscode_projects\\ForwardBackard_losses\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danibacaicoa\\vscode_projects\\ForwardBackard_losses\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danibacaicoa\\vscode_projects\\ForwardBackard_losses\\utils\\losses.py:80\u001b[0m, in \u001b[0;36mFwdBwdLoss.forward\u001b[1;34m(self, inputs, z)\u001b[0m\n\u001b[0;32m     78\u001b[0m log_Ff \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(Ff)\u001b[38;5;66;03m#+1e-8)\u001b[39;00m\n\u001b[0;32m     79\u001b[0m B_log_Ff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m log_Ff\n\u001b[1;32m---> 80\u001b[0m L \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(B_log_Ff[z,\u001b[38;5;28mrange\u001b[39m(B_log_Ff\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m#L = - torch.sum(B_log_Ff[z,range(B_log_Ff.size(1))]+1e-10)\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m L\n",
      "File \u001b[1;32mc:\\Users\\danibacaicoa\\vscode_projects\\ForwardBackard_losses\\.venv\\Lib\\site-packages\\torch\\fx\\traceback.py:72\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\traceback.py:232\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 232\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\traceback.py:395\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f, lineno \u001b[38;5;129;01min\u001b[39;00m frame_gen:\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f, (lineno, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_from_extended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_locals\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\traceback.py:434\u001b[0m, in \u001b[0;36mStackSummary._extract_from_extended_frame_gen\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    430\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    431\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals,\n\u001b[0;32m    432\u001b[0m         end_lineno\u001b[38;5;241m=\u001b[39mend_lineno, colno\u001b[38;5;241m=\u001b[39mcolno, end_colno\u001b[38;5;241m=\u001b[39mend_colno))\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 434\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(reps):\n",
    "    base_dir = \"Datasets/weak_datasets\"\n",
    "    if corr_n is not None:\n",
    "        folder_path = os.path.join(base_dir, f'{dataset}_{corruption}_p_+{corr_p}p_-{corr_n}')\n",
    "    else:\n",
    "        folder_path = os.path.join(base_dir, f'{dataset}_{corruption}_p{corr_p}')\n",
    "    f = open(folder_path + f'/Dataset_{i}.pkl','rb')\n",
    "    Data,Weak = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "    \n",
    "    if loss_type == 'Backward':\n",
    "        loss_fn = losses.FwdBwdLoss(Weak.Y,np.eye(Weak.c))\n",
    "    elif loss_type == 'Forward':\n",
    "        loss_fn = losses.FwdBwdLoss(np.eye(Weak.d),Weak.M)\n",
    "    elif loss_type == 'EM':\n",
    "        loss_fn = losses.EMLoss(Weak.M)\n",
    "    elif loss_type == 'LBL':\n",
    "        loss_fn = losses.LBLoss()\n",
    "    elif loss_type == 'Backward_opt':\n",
    "        loss_fn = losses.FwdBwdLoss(Weak.Y_opt,np.eye(Weak.c))\n",
    "    elif loss_type == 'Backward_conv':\n",
    "        loss_fn = losses.FwdBwdLoss(Weak.Y_conv,np.eye(Weak.c))\n",
    "    elif loss_type == 'Backward_opt_conv':\n",
    "        loss_fn = losses.FwdBwdLoss(Weak.Y_opt_conv,np.eye(Weak.c))\n",
    "    elif loss_type == 'OSL':\n",
    "        loss_fn = losses.OSLCELoss()\n",
    "    \n",
    "    if loss_type == 'OSL':\n",
    "        Data.include_weak(Weak.w)\n",
    "    else:\n",
    "        Data.include_weak(Weak.z)\n",
    "\n",
    "    \n",
    "    trainloader,testloader = Data.get_dataloader(weak_labels = 'weak')\n",
    "\n",
    "    print(Data.num_features)\n",
    "\n",
    "\n",
    "    #trainloader,testloader = Data.get_dataloader()\n",
    "    mlp = MLP(Data.num_features, [Data.num_features], Weak.c, dropout_p=0.3, bn = True, activation='tanh')\n",
    "    optim = torch.optim.Adam(mlp.parameters(), lr=1e-3)\n",
    "    mlp,results = train_and_evaluate(mlp,trainloader,testloader,optimizer=optim,loss_fn=loss_fn,corr_p=corr_p,num_epochs=100,sound=10,rep=i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Bwd = FwdBwdLoss(pinv(M),I_c)\n",
    "# Fwd = FwdBwdLoss(I_d,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as CSV at: Results\\image_pll_p0.5\\Forward.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res_dir = f\"Results/{dataset}_{corruption}\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "if corr_n is not None:\n",
    "    file_name = f'{loss_type}_p_+{corr_p}p_-{corr_n}.csv'\n",
    "else:\n",
    "    file_name = f'{loss_type}_p_+{corr_p}p_-{corr_n}.csv'\n",
    "file_path = os.path.join(res_dir, file_name)\n",
    "results.to_csv(file_path, index=False)\n",
    "\n",
    "print(f'DataFrame saved as CSV at: {file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_detached_loss</th>\n",
       "      <th>test_detached_loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>loss_fn</th>\n",
       "      <th>repetition</th>\n",
       "      <th>initial_lr</th>\n",
       "      <th>actual_lr</th>\n",
       "      <th>corr_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.469290</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.066955</td>\n",
       "      <td>0.090892</td>\n",
       "      <td>Adam</td>\n",
       "      <td>FwdBwdLoss</td>\n",
       "      <td>9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.441603</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.065961</td>\n",
       "      <td>0.089786</td>\n",
       "      <td>Adam</td>\n",
       "      <td>FwdBwdLoss</td>\n",
       "      <td>9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.413559</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.065322</td>\n",
       "      <td>0.088971</td>\n",
       "      <td>Adam</td>\n",
       "      <td>FwdBwdLoss</td>\n",
       "      <td>9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.388708</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.064642</td>\n",
       "      <td>0.088314</td>\n",
       "      <td>Adam</td>\n",
       "      <td>FwdBwdLoss</td>\n",
       "      <td>9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.371164</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.063951</td>\n",
       "      <td>0.087665</td>\n",
       "      <td>Adam</td>\n",
       "      <td>FwdBwdLoss</td>\n",
       "      <td>9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>2.707886</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.035038</td>\n",
       "      <td>0.062313</td>\n",
       "      <td>Adam</td>\n",
       "      <td>FwdBwdLoss</td>\n",
       "      <td>9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>2.713032</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.034726</td>\n",
       "      <td>0.061899</td>\n",
       "      <td>Adam</td>\n",
       "      <td>FwdBwdLoss</td>\n",
       "      <td>9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>2.714207</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.034487</td>\n",
       "      <td>0.061459</td>\n",
       "      <td>Adam</td>\n",
       "      <td>FwdBwdLoss</td>\n",
       "      <td>9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>2.714451</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.034288</td>\n",
       "      <td>0.061044</td>\n",
       "      <td>Adam</td>\n",
       "      <td>FwdBwdLoss</td>\n",
       "      <td>9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>2.725350</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.034119</td>\n",
       "      <td>0.060685</td>\n",
       "      <td>Adam</td>\n",
       "      <td>FwdBwdLoss</td>\n",
       "      <td>9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_acc  test_acc  train_detached_loss  \\\n",
       "0       1    3.469290   0.196429  0.142857             0.066955   \n",
       "1       2    3.441603   0.285714  0.214286             0.065961   \n",
       "2       3    3.413559   0.285714  0.261905             0.065322   \n",
       "3       4    3.388708   0.285714  0.285714             0.064642   \n",
       "4       5    3.371164   0.285714  0.285714             0.063951   \n",
       "..    ...         ...        ...       ...                  ...   \n",
       "95     96    2.707886   0.583333  0.500000             0.035038   \n",
       "96     97    2.713032   0.607143  0.500000             0.034726   \n",
       "97     98    2.714207   0.595238  0.547619             0.034487   \n",
       "98     99    2.714451   0.601190  0.547619             0.034288   \n",
       "99    100    2.725350   0.601190  0.571429             0.034119   \n",
       "\n",
       "    test_detached_loss optimizer     loss_fn  repetition  initial_lr  \\\n",
       "0             0.090892      Adam  FwdBwdLoss           9       0.001   \n",
       "1             0.089786      Adam  FwdBwdLoss           9       0.001   \n",
       "2             0.088971      Adam  FwdBwdLoss           9       0.001   \n",
       "3             0.088314      Adam  FwdBwdLoss           9       0.001   \n",
       "4             0.087665      Adam  FwdBwdLoss           9       0.001   \n",
       "..                 ...       ...         ...         ...         ...   \n",
       "95            0.062313      Adam  FwdBwdLoss           9       0.001   \n",
       "96            0.061899      Adam  FwdBwdLoss           9       0.001   \n",
       "97            0.061459      Adam  FwdBwdLoss           9       0.001   \n",
       "98            0.061044      Adam  FwdBwdLoss           9       0.001   \n",
       "99            0.060685      Adam  FwdBwdLoss           9       0.001   \n",
       "\n",
       "    actual_lr  corr_p  \n",
       "0       0.001     0.5  \n",
       "1       0.001     0.5  \n",
       "2       0.001     0.5  \n",
       "3       0.001     0.5  \n",
       "4       0.001     0.5  \n",
       "..        ...     ...  \n",
       "95      0.001     0.5  \n",
       "96      0.001     0.5  \n",
       "97      0.001     0.5  \n",
       "98      0.001     0.5  \n",
       "99      0.001     0.5  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
